% VLDB template version of 2020-08-03 enhances the ACM template, version 1.7.0:
% https://www.acm.org/publications/proceedings-template
% The ACM Latex guide provides further information about the ACM template

\documentclass[sigconf, nonacm]{acmart}
\usepackage{fontspec}
\usepackage{balance}
% \usepackage{xeCJK}
\usepackage{enumitem}
\usepackage{multirow}
% \usepackage{svg} % For SVG support
\usepackage{graphicx}
\usepackage{microtype}  %处理换行

\usepackage{subcaption} % 需要subcaption宏包支持子图
% \newtheorem{definition}{DEFINITION} % 定义“定义”环境
% % \newtheorem{example}{例} % 定义“例”环境，不与“定义”共享编号
% %% The following content must be adapted for the final version
% % paper-specific
\newcommand\vldbdoi{XX.XX/XXX.XX}
\newcommand\vldbpages{XXX-XXX}
% issue-specific
\newcommand\vldbvolume{14}
\newcommand\vldbissue{1}
\newcommand\vldbyear{2020}
% should be fine as it is
\newcommand\vldbauthors{\authors}
\newcommand\vldbtitle{\shorttitle} 
% leave empty if no availability url should be set
\newcommand\vldbavailabilityurl{URL_TO_YOUR_ARTIFACTS}
% whether page numbers should be shown or not, use 'plain' for review versions, 'empty' for camera ready
\newcommand\vldbpagestyle{plain} 

\begin{document}
\begin{sloppypar}
    

\title{An Experimental Evaluation of Hybrid Query Algorithms}

%%
%% The "author" command and its associated commands are used to define the authors and their affiliations.
% \author{Ben Trovato}
% \affiliation{%
%   \institution{Institute for Clarity in Documentation}
%   \streetaddress{P.O. Box 1212}
%   \city{Dublin}
%   \state{Ireland}
%   \postcode{43017-6221}
% }
% \email{trovato@corporation.com}

% \author{Lars Th{\o}rv{\"a}ld}
% \orcid{0000-0002-1825-0097}
% \affiliation{%
%   \institution{The Th{\o}rv{\"a}ld Group}
%   \streetaddress{1 Th{\o}rv{\"a}ld Circle}
%   \city{Hekla}
%   \country{Iceland}
% }
% \email{larst@affiliation.org}

% \author{Valerie B\'eranger}
% \orcid{0000-0001-5109-3700}
% \affiliation{%
%   \institution{Inria Paris-Rocquencourt}
%   \city{Rocquencourt}
%   \country{France}
% }
% \email{vb@rocquencourt.com}

% \author{J\"org von \"Arbach}
% \affiliation{%
%   \institution{University of T\"ubingen}
%   \city{T\"ubingen}
%   \country{Germany}
% }
% \email{jaerbach@uni-tuebingen.edu}
% \email{myprivate@email.com}
% \email{second@affiliation.mail}

% \author{Wang Xiu Ying}
% \author{Zhe Zuo}
% \affiliation{%
%   \institution{East China Normal University}
%   \city{Shanghai}
%   \country{China}
% }
% \email{firstname.lastname@ecnu.edu.cn}

% \author{Donald Fauntleroy Duck}
% \affiliation{%
%   \institution{Scientific Writing Academy}
%   \city{Duckburg}
%   \country{Calisota}
% }
% \affiliation{%
%   \institution{Donald's Second Affiliation}
%   \city{City}
%   \country{country}
% }
% \email{donald@swa.edu}
\author{Ben Trovato$^1$, Lars Th{\o}rv{\"a}ld$^2$, Valerie B\'eranger$^3$, J\"org von \"Arbach$^3$, Wang Xiu Ying$^3$, Donald Fauntleroy Duck$^3$}

\affiliation{%
  \institution{1. Institute for Clarity in Documentation, Ireland}
  \institution{2. The Th{\o}rv{\"a}ld Group, Iceland}
  \institution{3. Inria Paris-Rocquencourt, France}
}

\email{trovato@corporation.com, larst@affiliation.org, vb@rocquencourt.com, jaerbach@uni-tuebingen.edu, firstname.lastname@ecnu.edu.cn, donald@swa.edu}

%
% The abstract is a short summary of the work to be presented in the
% article.
\begin{abstract}
% Approximate Nearest Neighbor (ANN) search is a foundational technique in fields such as recommendation systems and information retrieval. However, in practical applications, users not only expect search results to be similar to the query in vector space but also to satisfy specific constraints, such as price ranges or categories. To meet these demands, researchers have proposed various hybrid query algorithms, including attribute filtering and range filtering. However, especially for attribute filtering, existing datasets often lack attribute values, and different researchers use varied testing configurations with simplified attribute value settings in their evaluations. Therefore, we select multiple real-world datasets and generate rich attribute values for various query scenarios, establishing a unified and comprehensive evaluation framework to compare these algorithms. Our study establishes a systematic taxonomy of hybrid query algorithms, exhaustively evaluates their time-space tradeoffs, performance, and robustness, and ultimately provides practical recommendations for different application scenarios.

Recent studies have shown that hybrid queries, including attribute filtering and range filtering, hold significant practical value. However, current evaluation efforts lack a unified benchmark and comprehensive testing. Existing research has failed to cover mainstream algorithms and has not systematically compared or deeply analyzed different methods. To address this issue, we have designed a complete evaluation framework for hybrid queries. Our study introduces more than ten hybrid query algorithms and systematically classifies them based on multiple dimensions such as index structure and filtering strategy, providing a reference for the categorization of hybrid queries. In the experimental section, for attribute filtering, we constructed standardized attribute sets, enabling a unified comparison of algorithms in terms of index construction efficiency, query performance, and robustness. For range filtering, we systematically tested the algorithms' performance in these three aspects by varying the query ranges. Additionally, we conducted an in-depth analysis of the experimental results based on the underlying principles of the algorithms. The extensive experimental results reveal the strengths and weaknesses of each algorithm. Based on these findings, we have developed a set of practical guidelines for algorithm selection, offering reliable references for different application scenarios. Furthermore, we have identified potential directions for improvement to address the current limitations of these algorithms.
\vspace{-0.2cm}
\end{abstract}


\maketitle

%%% do not modify the following VLDB block %%
%%% VLDB block start %%%
\pagestyle{\vldbpagestyle}
\begingroup\small\noindent\raggedright\textbf{PVLDB Reference Format:}\\
\vldbauthors. \vldbtitle. PVLDB, \vldbvolume(\vldbissue): \vldbpages, \vldbyear.\\
\href{https://doi.org/\vldbdoi}{doi:\vldbdoi}
\vspace{-0.1cm}
\endgroup
\begingroup
\renewcommand\thefootnote{}\footnote{\noindent
This work is licensed under the Creative Commons BY-NC-ND 4.0 International License. Visit \url{https://creativecommons.org/licenses/by-nc-nd/4.0/} to view a copy of this license. For any use beyond those covered by this license, obtain permission by emailing \href{mailto:info@vldb.org}{info@vldb.org}. Copyright is held by the owner/author(s). Publication rights licensed to the VLDB Endowment. \\
\raggedright Proceedings of the VLDB Endowment, Vol. \vldbvolume, No. \vldbissue\ %
ISSN 2150-8097. \\
\href{https://doi.org/\vldbdoi}{doi:\vldbdoi} \\
}\addtocounter{footnote}{-1}\endgroup
%%% VLDB block end %%%

%%% do not modify the following VLDB block %%
%%% VLDB block start %%%
\ifdefempty{\vldbavailabilityurl}{}{
\vspace{.3cm}
\begingroup\small\noindent\raggedright\textbf{PVLDB Artifact Availability:}\\
The source code, data, and/or other artifacts have been made available at \url{https://github.com/zhujx001/Hybrid-ANNS}.
\endgroup
}
%%% VLDB block end %%%

\section{Introduction}

Nearest Neighbor (NN) search \cite{cover1967nearest} aims to find the closest vector in a given space and serves as a fundamental algorithm in vector retrieval, with widespread applications in recommendation systems  \cite{monolith, Airbnb, Related_Pins_at_Pinterest, wang2018billion, pal2020pinnersage, okura2017embedding}  and image retrieval \cite{wang2012scalable}.
% 需要添加引用，下面这段
However, with the exponential growth of data volume and the increasing dimensionality of vectors \cite{weber1998quantitative}, traditional NN search methods struggle to meet the demands of real-time search. To address this issue, researchers have turned to more efficient approaches—Approximate Nearest Neighbor search ~\cite{arya1998optimal,beis1997shape,gionis1999similarity,malkov2018efficient}. ANN algorithms significantly improve search efficiency by constructing effective indexing structures, albeit at the cost of reduced accuracy.

Nevertheless, as application scenarios grow increasingly complex, simple ANN search can no longer satisfy all practical needs. For instance, as shown in Figure\ref{fig:hybrid ANNS}, users on e-commerce platforms may search for clothing items by retrieving visually similar products based on an image. Additionally, users may impose further requirements such as price, color, or brand preferences. Such scenarios necessitate a retrieval system capable of simultaneously addressing vector similarity (e.g., product image) and attribute constraints (e.g., brand name) \cite{tian2023approximate}. When the constraint involves a specific attribute value, this problem is referred to as Attribute Filtering Approximate Nearest Neighbor (AF-ANN) search ~\cite{NHQ,Filtered-diskann} . For example, a user may seek a green piece of clothing. If the constraint involves a range condition, it is termed Range Filtering Approximate Nearest Neighbor (RF-ANN) search  ~\cite{serf,iRangeGraph}. For instance, filtering clothes priced between $100 and $200. To meet these application demands, hybrid query \cite{JD-e-commerce, analyticdb} techniques have emerged. Hybrid queries integrate vector retrieval with conditional filtering, optimizing their interaction to significantly enhance efficiency and flexibility in complex query scenarios.




% However, as application scenarios become more complex, simple ANN search is no longer sufficient to meet all practical needs. New requirements have emerged for ANN search systems. For example, as Figure \ref{fig:hybrid ANNS}, a user on an e-commerce platform may search for a dress by retrieving similar items based on an image. Additionally, the user can apply structured attribute filters such as price, color, or brand. This scenario necessitates a retrieval system that satisfies both vector similarity and attribute constraints \cite{tian2023approximate}. When the constraint is a Boolean condition—e.g., the user specifically requires a green dress—the problem is referred to as Attribute Filtering Approximate Nearest Neighbor (AF-ANN) search ~\cite{NHQ,Filtered-diskann} problem. If the constraint is a range condition, such as filtering dresses priced between 100 and 200, it becomes the Range Filtering Approximate Nearest Neighbor (RF-ANN) search ~\cite{serf,iRangeGraph} problem. To address such cases, hybrid query \cite{JD-e-commerce, analyticdb} has been proposed. It jointly optimizes vector retrieval and conditional filtering. This approach significantly improves efficiency and flexibility in complex query scenarios.
\begin{figure*}
    \centering
    \setlength{\abovecaptionskip}{0cm}
    \setlength{\belowcaptionskip}{-0.4cm}
    \includegraphics[width=\textwidth]{figures/hybrid ANNS.pdf}
    \caption{Hybrid query example}
    % \vspace{-10pt} % 调整这个值来缩小空隙
    \label{fig:hybrid ANNS}
\end{figure*}
\subsection{Motivation}
% 近年来，混合查询算法发展迅速，已有多种属性过滤或范围过滤工作被提出。尽管 BigANN 2023 大赛\cite{bigann2023}的 filter 赛道对部分算法进行了性能测试，但其评估仍存在局限性：1) 参赛算法数量有限，未能覆盖当前主流方法；2) 仅评估单属性和双属性查询，未涉及更复杂的多属性场景；3) 测试数据集的属性分布不够全面。此外，不同算法在索引构建的时空开销、查询性能随属性数量变化的表现、以及对不同属性分布的适应性等方面尚缺乏系统性评估。目前，大多数研究仅关注属性过滤或范围查询的单一问题，而未能全面衡量混合查询的整体性能。为此，我们基于混合查询进行完整实验评估，全面分析不同算法在索引构建成本、查询效率及鲁棒性等方面的表现。
In recent years, hybrid query algorithms have developed rapidly, giving rise to numerous attribute filtering ~\cite{NHQ,diskann} and range-filtering algorithms \cite{serf,iRangeGraph}. In practical applications, the performance of hybrid query algorithms is influenced not only by unstructured data but also closely related to structured data. For attribute filtering algorithms, factors such as the number of base attributes, the number of query attributes, attribute distribution \cite{UNG}, and attribute selectivity \cite{ACORN} significantly impact algorithm performance. As for range filtering algorithms, the size of the query range and the characteristics of different datasets also play an important role in determining algorithm performance.


% In recent years, hybrid query algorithms have advanced rapidly, with numerous algorithms  proposed for attribute filtering and range filtering. 
% In practice, the performance of hybrid query algorithms is also influenced by the characteristics of structured data. For attribute filtering algorithms, factors such as the number of base attributes, the number of query attributes, attribute distributions \cite{UNG}, and attribute selectivity \cite{ACORN} all affect actual performance. For range filtering algorithms, query range size and different datasets will affect the performance of the algorithm.
Despite BigANN 2023 \cite{bigann2023}  evaluating the performance of some algorithms, its study still has several notable limitations:
1)The evaluation covers a limited number of algorithms and fails to comprehensively include mainstream methods. For instance, NHQ and Filtered-DiskANN in attribute filtering algorithms have not been assessed.
2)It focuses only on single-attribute and dual-attribute query scenarios, neglecting the more complex demands of multi-attribute queries. In real-world applications, an object typically involves multiple attributes. For example, in e-commerce scenarios, users often specify multiple attributes (e.g., color, brand, price range, etc.) simultaneously when searching.
3)It does not evaluate algorithm performance under different attribute distributions. However, variations in attribute distribution may directly affect the filtering strategies and index construction efficiency of hybrid query algorithms.

Moreover, aside from BigANN, there is currently a lack of systematic evaluation specifically targeting hybrid query algorithms. To fill this research gap, we conducted a comprehensive experimental evaluation of hybrid query algorithms, analyzing the index construction costs and query efficiency across different scenarios. Additionally, we further assessed the robustness of each algorithm under varying conditions.



% Although the filter track of the BigANN 2023 competition \cite{bigann2023} evaluated the performance of some algorithms, its assessment has several limitations: 
% 1) The number of evaluated algorithms is limited, failing to cover mainstream methods. Mainstream attribute filtering algorithms such as NHQ and Filtered-DiskANN were not evaluated.
% 2) The evaluation focuses only on single-attribute and dual-attribute queries, without considering more complex multi-attribute scenarios. However, in actual applications, an object often involves multiple attributes, and the same is true for queries. For example, in e-commerce scenarios, users often specify multiple attributes (such as color, brand, price range, etc.) for search at the same time.
% 3) It did not include algorithm performance under different attribute distributions. Different distribution of attributes may have a direct impact on the filtering strategy and index construction of the hybrid query algorithm.
% In addition, there is no relevant research to summarize and evaluate the relevant algorithms for hybrid queries.

% Furthermore, with the exception of the BigANN competition, there has been no dedicated study that provides a comprehensive review and evaluation of hybrid query algorithms. 
% In addition, apart from the BigANN competition, no dedicated evaluation of hybrid query algorithms exists. To fill this gap, we conduct a comprehensive experimental evaluation of hybrid query algorithms, analyzing index construction overhead and query efficiency across diverse scenarios. In addition, we assess the robustness of each algorithm.

% Moreover, there has been no systematic evaluation of different algorithms in terms of index construction overhead, query performance across varying attribute numbers, and adaptability to different attribute distributions. Most existing studies focus solely on attribute filtering or range filtering, without providing a holistic assessment of hybrid queries. To address this gap, we conduct a comprehensive experimental evaluation of hybrid queries, analyzing the indexing overhead, query efficiency, and robustness of different algorithms.
% In recent years, hybrid query algorithms have advanced rapidly, but their differences in attribute distribution adaptability and multi-attribute query performance have not been systematically evaluated. Although the filter track of the BigANN 2023 competition\cite{bigann2023} tested the performance of some algorithms, its evaluation scope has several limitations. First, the number of participating algorithms was limited, failing to cover the mainstream hybrid query algorithms. Second, the test dataset lacked diversity in attribute cardinality and attribute distribution, which may not fully reflect algorithm performance under different data characteristics. Third, the evaluation focused only on single-attribute and two-attribute query, without considering more complex multi-attribute scenarios, limiting the generalizability and practical value of the results. Moreover, the competition did not include evaluations of range filtered algorithms.

% Based on this background, we aim to design a series of systematic experiments. We will construct diverse datasets for attribute filtered query and comprehensively evaluate mainstream hybrid query algorithms.
\subsection{Our Contributions}
% The core contribution of this study lies in the systematic evaluation of hybrid query algorithms, which specifically includes the following aspects:
% We focus on ANN search in hybrid query scenarios. We systematically review and evaluate existing algorithms and systems. Our main contributions are summarized in four parts:
This study focuses on the problem of ANN search in hybrid query scenarios and provides a comprehensive review and evaluation of existing algorithms and systems. The main contributions are summarized in the following four aspects.

(1)\textbf{ Systematic Classification and Overview.}
We systematically classify more than ten representative attribute filtering algorithms from multiple dimensions, including index structure, filtering strategy, Boolean logic support, and index construction methods. Additionally, we survey range filtering algorithms and provide an overview of widely used vector retrieval libraries (e.g., Faiss) and vector databases (e.g., Milvus, PASE, VBASE). These efforts provide a unified reference framework for future research.

(2)\textbf{ Evaluation of Attribute-Filtering Algorithms.}
% We select several representative algorithms for Attribute Filtered ANN Search. Using six real-world datasets, we evaluate their performance under different settings, such as the number of attributes, attribute distribution, and selectivity. We analyze their performance in terms of index construction time, index size,peak memory usage, query speed (QPS), and query accuracy. We also discuss their robustness and adaptability in complex scenarios.
We experimentally evaluate 13 attribute filtering ANN algorithms on six real-world datasets. By analyzing the performance variations of these algorithms under different numbers of attributes, attribute distributions, and selectivity conditions, we reveal the strengths and weaknesses of each algorithm. Furthermore, we explore the robustness and adaptability of these algorithms under complex query conditions. Evaluation metrics include index construction time, index size, peak memory usage,QPS and search accuracy.

(3)\textbf{ Evaluation of Range-Filtering Algorithms.}
% We evaluate five main algorithms (SeRF, WinFilter, iRangeGraph, DSG, and UNIFY) for Range Filtered ANN Search. We run experiments on three large-scale datasets with different query range settings. We compare their performance in index construction, storage usage, and query efficiency. We also study the effect of index structures on algorithm performance. This provides useful insights for future improvements.
We benchmark five mainstream range filtering ANN algorithms on three large-scale datasets, using varying query range settings in the experiments. The results demonstrate the performance of these algorithms in terms of index construction efficiency, storage overhead, and query performance. Additionally, we conduct an in-depth analysis of how index structures impact algorithm performance, providing valuable insights for algorithm design.

(4)\textbf{ Recommendations and Challenges.}
Based on the experimental results, we provide algorithm selection recommendations for common application scenarios and highlight key challenges in the field of hybrid queries. These challenges include limited Boolean logic support, the lack of multi-attribute range filtering capabilities, the high indexing costs of graph-based methods, and the sensitivity of algorithms to data distribution. Currently, few methods simultaneously support both attribute filtering and range filtering, pointing to potential directions for future research.

\section{PRELIMINARIES}

\subsection{Problem Definition}

We first define the Nearest Neighbor (NN) search problem.

\begin{definition}[NN Search]

Let \( D = \{v_1, \ldots, v_n\} \) be a dataset of \( n \) \( d \)-dimensional vectors. Given a query \( Q = (q_v, k) \), where \( q_v \) is the query vector and \( k \) is a positive integer, the NN search aims to return a set \( R \subseteq D \) with \( |R| = k \), such that for any \( x \in R \) and \( y \in D \setminus R \), \( \textit{dist}\!\left(q_v, x\right) \leq \textit{dist}\!\left(q_v, y\right) \). Here, \( \textit{dist}\!\left(\cdot, \cdot\right) \) denotes the distance metric, and we adopt Euclidean distance in this paper.
\end{definition}

However, to address the curse of dimensionality faced by NN search \cite{dimcurse}, existing researches focus on approximate solutions, known as ANN  search. We typically use $\text{Recall}@k = \frac{|R \cap \hat{R}|}{k}$ to evaluate the accuracy of ANN search algorithms, where $R$ denotes the true top-$k$ nearest neighbors of the query, $\hat{R}$ denotes the approximate top-$k$ nearest neighbors returned by the ANN search algorithm.

As the complexity of real-world application requirements increases, NN search has evolved into hybrid NN search with attribute constraints. Depending on the nature of the attribute constraints, hybrid NN search can be divided into two categories: 1) Attribute Filtering Nearest Neighbor (\textit{AF-NN}) search. 2) Range Filtering Nearest Neighbor (\textit{RF-NN}) search. We provide their formal definitions below.

\begin{definition}[AF-NN Search]
Let \( D = \{(v_1, s_1), \ldots, (v_n, s_n)\} \) be a dataset of \( n \) \( d \)-dimensional vectors, each associated with an attribute set \( s_i \). Given a query \( Q = (q_v, q_s, k) \), where \( q_s \) is the query attribute set, the AF-NN search aims to return a set \( R \subseteq D_s \) with \( |R| = k \), such that for any \( x \in R \) and \( y \in D_s \setminus R \), \( \textit{dist}(q_v, x) \leq \textit{dist}(q_v, y) \), where \( D_s = \{ v_i \mid (v_i, s_i) \in D \land q_s \subseteq s_i \} \).
\end{definition}

We further classify AF-NN search according to the number of the attribute set \( s_i \): 1) Single-Attribute Filtering Nearest Neighbor (\textit{SAF-NN}) search, where $\forall i,\, |s_i| = 1$. 2) Multi-Attribute Filtering Nearest Neighbor (\textit{MAF-NN}) search, where $\exists i,\, |s_i| > 1$.

\begin{definition}[RF-NN Search]

Let \( D = \{(v_1, s_1), \ldots, (v_n, s_n)\} \) be a dataset of \( n \) \( d \)-dimensional vectors, each associated with an attribute value \( a_i \). Given a query \( Q = (q_v, [a_{\min}, a_{\max}], k) \), where \( a_{\min} \) and \( a_{\max} \) denote the lower and upper bounds of the query range, respectively, the RF-NN search aims to return a set \( R \subseteq D_a \) with \( |R| = k \), such that for any \( x \in R \) and \( y \in D_a \setminus R \), \( \textit{dist}(q_v, x) \leq \textit{dist}(q_v, y) \), where \( D_a = \{ v_i \mid (v_i, a_i) \in D \land a_{\min} \leq a_i \leq a_{\max} \} \).
\end{definition}



Similar to the conventional ANN search, most existing studies focus on approximate solutions for hybrid NN search, referred to as hybrid ANN search, which includes both \textit{AF-ANN} search and \textit{RF-ANN} search.



\subsection{Index Structures in ANN Search}

Current hybrid query methods mainly adopt graph-based ~\cite{nsw,kgraph,nsg,fanng,ngt} or Inverted File Index (IVF)-based \cite{PQ} index structures. We briefly introduce the fundamental principles of these two types in the following.

\vspace{1em}
\noindent\textbf{\underline{Graph.}}
Graph-based ANN search algorithms accelerate queries by building graph indexes on datasets. As illustrated in Figure~\ref{fig:graph}, each data point in the dataset corresponds to a point in the graph, and neighboring vertices (e.g., $a$ and $b$) are connected via edges based on their distance $\textit{dist}(a, b)$. In the graph index, each point maintains connections only to its nearest neighbors to preserve query efficiency. For instance, in Figure~\ref{fig:graph}, the gray point $c$ is connected to five neighbors $(a, b, d, e, f)$ and can traverse to them via corresponding edges.

Given a query point $q$, the graph-based ANN search typically follows a greedy search strategy to find the $k$ nearest neighbors. For illustration, consider the case where $k = 1$ (i.e., finding the single nearest neighbor of $q$): The algorithm initiates the search from an entry point (the gray point $c$). If there exists a neighbor $n$ (the point $f$) of the current point such that $\textit{dist}(n, q) < \textit{dist}(c, q)$, the algorithm updates the current point to $n$. This process is iteratively repeated—always moving to the neighbor closest to $q$—until no neighbor is found that is closer than the current point. The final point reached (the blue point $j$) is returned as the approximate nearest neighbor of $q$.

\vspace{1em}
\noindent\textbf{\underline{IVF.}}
IVF-based ANN search algorithms improve computational efficiency by partitioning the dataset into clusters and restricting the search to clusters nearest to the query point. Specifically, as shown in Figure~\ref{fig:ivf}, IVF first selects a subset of data points and applies a clustering algorithm (e.g., K-Means) to obtain a set of centroids $(C_0, C_1, ..., C_6)$, each representing a distinct cluster. Every data point (gray dots) is then assigned to the cluster corresponding to its nearest centroid based on the distance metric, thereby forming the index structure.

During the query process, given a query point $q$, the algorithm computes distances between $q$ and all centroids, selects a small number of the closest centroids ($C_0, C_1, C_2$), and then performs a search only within the associated clusters to identify the approximate nearest neighbors.

\begin{figure}
    \begin{subfigure}{0.60\columnwidth}
        \centering
        \setlength{\abovecaptionskip}{0cm}
        \setlength{\belowcaptionskip}{-0.3cm}
        \includegraphics[width=\linewidth]{figures/graph.pdf}
        \caption{Graph Index}
        \label{fig:graph}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.38\columnwidth}
        \centering
        \setlength{\abovecaptionskip}{0cm}
        \setlength{\belowcaptionskip}{-0.3cm}
        \includegraphics[width=\linewidth]{figures/ivf.pdf}
        \caption{IVF Index}
        \label{fig:ivf}
    \end{subfigure}
    % \vspace{-10pt} % 调整这个值来缩小空隙
    \setlength{\abovecaptionskip}{0cm}
    \setlength{\belowcaptionskip}{0.2cm}
    \caption{Graph index and IVF index}
    % \vspace{-2em} % 调整这个值来缩小空隙
\end{figure}


\section{Overview of Hybrid query Algorithms}

\setlength{\textfloatsep}{0cm}
\setlength{\floatsep}{0cm}
\begin{table*}[t]
	\centering
        \setlength{\abovecaptionskip}{0.05cm}
        %\setlength{\belowcaptionskip}{-0.3cm}
        
	\caption{Comparison of AF-ANN search algorithms}
	\small
	\label{tab:compair_1}
    \begin{tabular}{|l|l|c|c|c|c|c|c|c|}
		\hline
        \textbf{Algorithm} & \textbf{Base} & \textbf{Filter Type} & \textbf{AND} & \textbf{OR} & \textbf{Flexible Attributes} & \textbf{Complex Boolean} & \textbf{Dynamic Insert} & \textbf{Multi Thread} \\
		\hline
         NHQ & Graph & C & Y & N& N& N & N & N \\
         FilteredVamana & Graph & C & N & Y & Y & N & Y & Y \\
	StitchedVamana & Graph & C & N & Y & Y & N & N & Y  \\
        CAPS & IVF & C & Y & N & N & N & Y & Y \\
        ACORN & Graph & C & Y & Y & Y & Y & Y & Y \\
       UNG & Graph & B & Y & Y & Y & N & Y & Y \\ 
        Puck & IVF & B & Y & Y & Y & N & Y & Y \\
        % ParlayANN & Graph+IVF & B & N & N & Y & N & N & Y \\
		
		\hline
	\end{tabular}

    \vspace{0.2em}
	\centering
    \footnotesize{
	\begin{minipage}{\linewidth}
		\textsuperscript{A} Post-filtering, 
		\textsuperscript{B} Pre-filtering, 
		\textsuperscript{C} Simultaneous filtering, 
		\textsuperscript{Y} Support, 
		\textsuperscript{N} Unsupport. 
		\textit{Base} indicates that the hybrid query algorithm is an improvement based on a specific ANN search algorithm. 
		\textit{AND} indicates whether the algorithm supports attribute filtering with AND operations. 
		\textit{OR} indicates whether the algorithm supports attribute filtering with OR operations. 
		\textit{Flexible Attributes} indicates whether the number of query attributes can differ from the number of attributes used during index construction. 
		\textit{Complex Boolean} refers to whether the algorithm supports advanced Boolean logic beyond just AND and OR, such as NOT or combinations like (A AND B) OR (C AND NOT D). 
		\textit{Dynamic} indicates whether the algorithm supports the operation of dynamically inserting data points.
	\end{minipage}}
    \vspace{-0.5cm}
\end{table*}


We provide an overview and analysis of over ten hybrid query methods, all drawn from recent research efforts, and collectively referred to as algorithms in the following text. Specifically, Section~3.1 describes methods based on attribute filtering, Section~3.2 discusses those based on range filtering, and Section~3.3 introduces vector libraries and databases that support both attribute and range filters.

\vspace{-10pt}
\subsection{Attribute Filtering Algorithms}

We summarize six attribute filtering algorithms and provide an intuitive comparison in Table~\ref{tab:compair_1}.

\vspace{1em}
\noindent\textbf{\underline{NHQ \cite{NHQ}.}}  
Traditional attribute filtering algorithms usually perform attribute constraints and ANN search separately. In contrast, NHQ is the first to implement simultaneous filtering, integrating both aspects into a unified framework. NHQ constructs an index based on a nearest neighbor graph and introduces a fusion distance that jointly captures vector similarity and attribute similarity. Leveraging this fusion distance, NHQ unifies vector similarity and attribute matching into a single comprehensive similarity measure and builds the graph accordingly. During the query process, NHQ efficiently prunes irrelevant edges via this composite index, enabling fast retrieval of results that satisfy both vector similarity and attribute constraints.

\vspace{1em}
\noindent\textbf{\underline{Filtered-DiskANN \cite{Filtered-diskann}.}}  
The effectiveness of NHQ may degrade when the number of attributes changes, as it affects the fusion distance computation. Filtered-DiskANN addresses this limitation.

Filtered-DiskANN also supports simultaneous filtering. Built upon the Vamana \cite{diskann} graph-based ANN index, it incorporates attribute information directly into the graph during index construction. This integration ensures that the index reflects both vector proximity and attribute constraints. Moreover, Filtered-DiskANN supports SSD-based storage, improving scalability.

Filtered-DiskANN proposes two index variants:  
1) \textbf{FilteredVamana}, which incrementally builds the graph index by inserting data points and dynamically adding edges, allowing adaptive expansion.  
2) \textbf{StitchedVamana}, which adopts a batch construction strategy—constructing separate Vamana subgraphs for each attribute, followed by merging and edge pruning.

A key limitation of Filtered-DiskANN is that while it supports both single-attribute and multi-attribute filtering, it only supports the Boolean OR logic for multi-attribute filtering, lacking support for Boolean AND logic.

\vspace{1em}
\noindent\textbf{\underline{CAPS \cite{CAPS}.}}  
As graph-based methods, NHQ and Filtered-DiskANN often result in large index sizes. CAPS addresses this issue by being the first simultaneous filtering algorithm based on spatial partitioning, significantly reducing index size.

CAPS introduces a hierarchical sub-partitioning algorithm inspired by Huffman trees, termed the Attribute Frequency Tree (AFT), to overcome the coarse granularity of traditional IVF-based methods. CAPS adopts a two-level partitioning strategy:  
1) The first level clusters vectors based on similarity using K-Means or learning-based methods such as BLISS.  
2) Within each cluster, AFT partitions data further based on attribute frequencies, enabling finer-grained indexing and improving query efficiency.

\vspace{1em}
\noindent\textbf{\underline{ACORN \cite{ACORN}.}}  
Above simultaneous filtering methods struggle with large-scale, unbounded, or unknown predicate sets.
%The above simultaneous filtering methods are less effective in scenarios involving large-scale, unbounded, or unknown predicate sets, where a predicate refers to a condition or rule used for filtering. 
ACORN addresses this issue by introducing a predicate-agnostic indexing framework.

ACORN is built upon HNSW \cite{hnsw}, a hierarchical graph-based ANN index. It supports high-cardinality and unrestricted predicate sets, overcoming the limitations of methods restricted to small-scale equality filters. It constructs a denser hierarchical graph by expanding node neighborhoods and prunes edges at lower levels to control index size. During querying, ACORN eliminates unnecessary distance computations by filtering out nodes that violate attribute constraints. This effectively maintains a nearest neighbor graph over valid nodes only. 
%During the query process, ACORN avoids unnecessary distance computations by filtering out nodes that do not meet attribute constraints, effectively simulating a nearest neighbor graph over valid nodes only.

ACORN includes two index variants:  
1) \textbf{ACORN-$\gamma$}, which expands neighbor lists during construction, increasing memory usage for higher performance.  
2) \textbf{ACORN-1}, which extends neighbor lists by considering second-hop neighbors during search, reducing index size with minor performance loss.

\vspace{1em}
\noindent\textbf{\underline{UNG \cite{UNG}.}} 
Graph-based methods(NHQ, Filtered-DiskANN, ACO-\\RN)do not guarantee result completeness, while CAPS lacks robustness when base and query vectors differ in attribute cardinality. UNG is proposed to overcome both limitations.

UNG is a unified framework that integrates diverse graph-based ANN indexes for hybrid query. It first groups the dataset by attribute sets, ensuring that vectors in each group share identical attributes. Then, it constructs a Label Navigating Graph (LNG) to encode inclusion relationships among attribute sets. Within each group, UNG builds graph-based ANN indexes (e.g., Vamana, HNSW) and connects them via cross-group edges to enable efficient cross-group search.

UNG supports Boolean filtering with two modes:  
1) The query attribute set is a subset of the data attribute set.  
2) The query attribute set exactly matches the data attribute set.



\vspace{1em}
\noindent\textbf{\underline{Puck \cite{puck}.}}  
While simultaneous filtering performs well in most scenarios, it may underperform when only a small portion of data satisfies attribute constraints. In such cases, a pre-filtering strategy—applying attribute constraints prior to ANN search—can be more effective.

Developed by Baidu, Puck utilizes two-level quantization for indexing. It maintains an attribute set for each cluster to track vector attributes. During the query process, it employs pre-filtering to exclude clusters without required attributes, thereby reducing the search space.
%Developed by Baidu, Puck adopts a pre-filtering approach and employs a multi-level filtering mechanism for hybrid query. Its index structure comprises four layers: the first two use vector quantization for training, while the latter two leverage product quantization.


\setlength{\textfloatsep}{0.1cm}
\setlength{\floatsep}{0cm}
\begin{table}[t]
	\centering
        \setlength{\abovecaptionskip}{0.05cm}
        %\setlength{\belowcaptionskip}{-0.3cm}
        \setlength{\textfloatsep}{0cm}
	\caption{Comparison of RF-ANN search algorithms}
	\small	% 只会影响当前组的内容
	\label{tab:range_algo}
    \begin{tabular}{|c|c|c|c|}
		\hline
		\textbf{Algorithm} & \textbf{Base} & \textbf{Dynamic Insert} & \textbf{Multi Thread} \\
		\hline
        DSG & Graph & Y & N \\
        iRange & Graph & N & Y \\
        SeRF & Graph & Y & Y \\
		UNIFY & Graph & Y & Y \\
		WinFilter & Graph & N & Y  \\
		\hline
	\end{tabular}

    \vspace{0.2em} % 调整间距
	\footnotesize{
            \begin{minipage}{\linewidth}
            \textsuperscript{Y} Support, 
            \textsuperscript{N} Unsupport.
            \textit{Base} indicates that the hybrid query algorithm is an improvement based on a specific ANN search algorithm. 
    		\textit{Dynamic} indicates whether the algorithm supports the operation of dynamically inserting data points.
            \end{minipage} 
        }
	
\end{table}

\subsection{Range Filtering Algorithms}

We introduce five representative range filtering algorithms and present a comparative overview in Table~\ref{tab:range_algo}.

\vspace{1em}
\noindent\textbf{\underline{SeRF \cite{serf}.}}  
Conventional RF-ANN search approaches typically follow one of two paradigms: 1) conducting ANN search first followed by attribute-based filtering; 2) filtering the dataset based on attribute ranges before performing ANN search. However, both approaches suffer from suboptimal performance. Building a separate neighbor graph (e.g., HNSW) for each attribute range could ensure efficient querying but incurs an $O(n^2)$ cost in constructing and storing $n$ graphs. Since many edges are shared across these graphs, SeRF introduces a validity-range aware design where each edge records the interval in which it is valid, indicating in which subgraphs the edge remains valid. This compresses $n$ graphs into a single unified graph, maintaining search effectiveness while significantly reducing memory and index construction overhead.

\vspace{1em}
\noindent\textbf{\underline{WinFilter \cite{winFilter}.}}  
Unlike SeRF, which focuses on graph compression, WinFilter proposes a structural partitioning framework called the $\beta$-Window Search Tree ($\beta$-WST). After the dataset is sorted by attribute values, it is partitioned into multiple intervals and organized into a tree structure. Each node in the tree corresponds to an attribute range and maintains a local ANN index (e.g., Vamana). For a range-filtering query, WinFilter only searches within nodes overlapping the query range and merges partial results. With a tree height of $O(\log n)$, each query accesses at most $O(\log n)$ sub-indexes, resulting in significant speedups.

\vspace{1em}
\noindent\textbf{\underline{iRange \cite{iRangeGraph}.}}  
To address the query efficiency degradation caused by the graph compression in SeRF, iRange adopts a more flexible strategy. Rather than prebuilding indexes for all possible ranges, it dynamically assembles a query-specific subgraph at runtime. iRange partitions the dataset into intervals based on attribute values and independently constructs a local graph for each interval, storing only edge information. During the query process, the relevant local graphs overlapping with the query range are merged into a temporary search graph, and a pruning strategy is applied to enable efficient search.

\vspace{1em}
\noindent\textbf{\underline{DSG \cite{DSG}.}}  
Most RF-ANN search methods, such as iRange and WinFilter, are designed for static datasets. SeRF allows incremental insertion but requires ordered attributes. DSG introduces the first dynamic RF-ANN framework supporting data insertion with unordered attributes while maintaining efficient range filtering.
DSG relies on two key data structures: 1) A rectangle tree partitions query space into rectangular regions, each corresponding to a group of queries sharing nearest neighbors. 2) A dynamic segment graph is a neighbor graph where each edge is annotated with its valid attribute range.
With these structures, only few regions need updates when inserting new data. During queries, the system considers only edges valid for current attribute range, boosting efficiency.



\vspace{1em}
\noindent\textbf{\underline{UNIFY \cite{UNIFY}.}}  
Unlike DSG, which relies on rectangle trees and range-aware edges, UNIFY adopts a segmentation-based approach and proposes a range query index structure. UNIFY introduces the Segmented Inclusive Graph (SIG), which partitions the dataset into segments by attribute and constructs an independent neighbor graph for each segment. These segment graphs are then integrated into a unified global graph. SIG adheres to a graph inclusiveness principle: any query subgraph can be composed from existing segment graphs, avoiding the need for range-specific index construction. Its hierarchical variant, HSIG, enhances SIG by incorporating the multilayer design of HNSW, skip lists, and edge bitmaps for efficient range localization and post-filter pruning. UNIFY supports three filtering strategies—pre-filtering, post-filtering, and  simultaneous filtering—enabling robust and flexible performance across diverse application scenarios.



\subsection{Vector Libraries and Databases}

The vector libraries and databases discussed in this section are not explicitly designed for hybrid query, but they support both attribute filtering and range filtering. Additionally, all the functionalities shown in Table 1 are also supported.

\vspace{1em}
\noindent\textbf{\underline{Faiss \cite{Faiss}.}}  
Faiss is a library designed for efficient similarity search and clustering of dense vectors. It supports various indexing structures, including IVF, Product Quantization (PQ) \cite{PQ}, and HNSW.

In hybrid query scenarios, Faiss supports vector search with an ID selector, which is a bitmap aligned with the dataset size. Users can generate this selector by first applying custom attribute filtering methods. During the query, Faiss excludes vectors based on the selector, enabling efficient integration of attribute filtering with ANN search.

% HQI~\cite{HQI} further proposes an optimization scheme for the IVF index in Faiss, improving efficiency in two aspects:  
% 1) Workload-Aware Vector Index: Constructs an attribute filtering tree using historical query workloads and vector cluster centroids to improve filtering efficiency.  
% 2) Batch Query Optimization: Groups queries sharing the same filter conditions, performs filtering once per group, and then conducts batch vector similarity computations using efficient matrix operations.  
% Since this paper does not focus on query workload optimization, we adopt only the batch optimization strategy in our analysis.
In addition, we adopted the batch optimization strategy of HQI~\cite{HQI} for the IVF index in Faiss. This strategy groups queries with the same filter conditions, performs filtering once per group, and then uses efficient matrix operations to perform batch vector similarity calculations.

\vspace{1em}
\noindent\textbf{\underline{PASE \cite{pase}.}}  
PASE is a vector indexing plugin for the PostgreSQL database \cite{postgresql13.4}, supporting two index types: IVF\_Flat \cite{johnson2019billion} and HNSW. By leveraging database capabilities, PASE enables both attribute filtering and range filtering. We focus on the post-filtering strategy based on HNSW.

When a query request is received, PASE first obtains a candidate set using the HNSW index. It then applies the filtering conditions from the WHERE clause to refine the results. However, since the candidate set has a fixed size, low-selectivity filters may result in fewer than $k$ results being returned.

\vspace{1em}
\noindent\textbf{\underline{VBASE \cite{vbase}.}}  
Similar to PASE, VBASE is a PostgreSQL-based vector indexing plugin supporting HNSW, SPTAG~\cite{sptag}, and SPANN~\cite{spann}. We focus on HNSW-based search.

VBASE adopts a post-filtering strategy. However, it employs an iterative filtering mechanism: during index traversal, each node is immediately checked against the WHERE clause, and non-matching nodes are discarded. This avoids the issue in PASE where the final result set may contain fewer than $k$ results.

\vspace{1em}
\noindent\textbf{\underline{Milvus \cite{milvus}.}}  
Unlike PASE and VBASE, which are database extensions, Milvus is an open-source vector database purpose-built for large-scale similarity search. It supports multiple index types, including HNSW, IVF\_Flat, and IVF\_PQ, and provides extensive optimization for real-world deployment.

Among its indexes, IVF\_Flat is commonly used due to its balance between performance and simplicity. In hybrid queries, Milvus first pre-filters the dataset using user-specified conditions, then traverses only the corresponding clusters for ANN search—similar to the ID selector mechanism of Faiss.

\section{Experiments}
\subsection{Experimental Setup}
\subsubsection{Datasets}

For attribute filtering tasks, we employ six real-world datasets widely adopted in existing literature: Msong~\cite{msong2011}, Audio~\cite{audio_unknown}, SIFT1M~\cite{sift2010}, GIST1M~\cite{sift2010}, GloVe~\cite{GloVe2015}, and Enron~\cite{enron2015}, covering a diverse range of domains. We independently generate attribute for each dataset.


For range filtering queries, we evaluate three widely used real-world datasets: Deep~\cite{yandex_deep_dataset}, YT-Audio~\cite{youtube8m_dataset}, and WIT~\cite{wit_dataset}. Following prior work~\cite{DSG}, we use the data point ID within each dataset as its attribute. This ensures that the data is initially sorted.

Table~\ref{tab:datasets_combined} summarizes the key characteristics of all datasets. In particular, we report the Local Intrinsic Dimensionality (LID)~\cite{Lid}, a commonly used metric to quantify dataset hardness. Following the standard evaluation protocol~\cite{LID2}, we randomly sample 10,000 data points from each dataset for LID computation. A higher LID indicates greater intrinsic complexity.

\setlength{\textfloatsep}{0.1cm}
\setlength{\floatsep}{0cm}
\begin{table}[t]
\centering
% \vspace{-6pt} % 调整这个值来缩小空隙
\setlength{\abovecaptionskip}{0.05cm}
\setlength{\textfloatsep}{0.cm}
\caption{Datassets}

\label{tab:datasets_combined}
\resizebox{\columnwidth}{!}{
\begin{tabular}{cccccc}
\toprule
Dataset & Dimension & Base Data & Queries & LID & Type \\
\midrule
Msong & 420 & 992,272 & 200 & 23& Audio \\[2pt]
Audio & 192 & 53,387 & 200 & 14& Audio \\[2pt]
SIFT1M & 128 & 1,000,000 & 10,000 & 19& Image \\[2pt]
GIST1M & 960 & 1,000,000 & 1,000 & 45& Image \\[2pt]
GloVe & 100 & 1,183,514 & 10,000 & 47& Text \\[2pt]
Enron & 1369 & 94,987 & 200 & 23& Text \\[2pt]
Deep & 96 & 1,000,000 & 10,000 & 22& Image \\[2pt]
YT-Audio& 128 & 1,000,000 & 10,000 & 15& Audio \\[2pt] 
WIT & 2048 & 1,000,000 & 40,300 & 48& Image \\[2pt]

\bottomrule
\end{tabular}
}
\end{table}



\subsubsection{Evaluation Metrics}

To comprehensively assess the overall performance of different algorithms, we adopt a multi-dimensional quantitative evaluation framework~\cite{compare}, which includes the following five core metrics:

\begin{enumerate}

    \item \textbf{Recall@k}: The proportion of overlap between the returned approximate $k$ nearest neighbors and the ground-truth $k$ nearest neighbors.
    \item \textbf{QPS (Queries Per Second)}: The number of queries processed per second.
    \item \textbf{Index Construction Time}: The total time required to transform the raw dataset into a queryable index structure.
    \item \textbf{Index Size}: The storage size of the persisted index on disk.
    \item \textbf{Peak Memory Usage}: The maximum memory consumption observed during the index construction phase.
\end{enumerate}

\subsubsection{Parameter Settings}

For all evaluated algorithms, we adopt the parameter settings recommended in the original paper and adjust the parameters related to search in order to obtain different recall and QPS.



\subsubsection{Platform}


We conduct all experiments on a server running Ubuntu 20.04, equipped with an AMD EPYC 7K62 processor (2.6GHz) and 256GB of RAM. Unless otherwise stated, we execute index construction with 32 threads to accelerate the process~\cite{benchmarkindex}. By default, queries run on a single thread; we also report results for 16-thread parallelism in specific scenarios.

We summarize the multi-threading capabilities of each algorithm in Table~\ref{tab:compair_1} and Table~\ref{tab:range_algo}. For vector database systems, we adopt a multi-process evaluation scheme (rather than multi-threaded execution), following the methodology proposed in VectorDBBench~\cite{VectorDBBench}, to better reflect their real-world performance characteristics.



%4.2
\subsection{Attribute Filtering}


%4.2.1
\subsubsection{Time and Space overhead of index construction}
% \subsubsection{\textbf{Attribute Filtering}}
\begin{figure}[t]
    \centering
        \setlength{\abovecaptionskip}{0.3cm}
        \setlength{\belowcaptionskip}{0cm}

    % 上面的图例，居中并可通过 hspace 调整左右位置
    \hspace*{15pt} % 可调整的参数，负值左移，正值右移，例如 -20pt 或 20pt
    \includegraphics[width=0.94\columnwidth]{figures/indexData/legend_only.pdf} % 图例图片路径
    \vspace{-12pt} % 使用负值拉近两张图的距离，可以根据需要调整
    
    \begin{subfigure}{\columnwidth}
        \centering
        \setlength{\abovecaptionskip}{0cm}
        
        \setlength{\belowcaptionskip}{-0.3cm}
        \includegraphics[width=\linewidth]{figures/indexData/exp_7_build_time_comparison_query1.pdf}
        \caption{Index construction time}
        \label{fig:build_time_comparison_query1}
    \end{subfigure}
    
    \vspace{0.3cm} % 增加间距

    \begin{subfigure}{\columnwidth}
        \centering
        \setlength{\abovecaptionskip}{0cm}
        \setlength{\belowcaptionskip}{-0.3cm}
        \includegraphics[width=\linewidth]{figures/indexData/exp_7_index_size_mb_comparison_query1.pdf}
        \caption{Index size}
        \label{fig:index_size_mb_comparison_query1}
    \end{subfigure}

    \vspace{0.3cm} % 增加间距

    \begin{subfigure}{\columnwidth}
        \centering
        \setlength{\abovecaptionskip}{0cm}
        \setlength{\belowcaptionskip}{-0.3cm}
        \includegraphics[width=\linewidth]{figures/indexData/exp_7_memory_mb_comparison_query1.pdf}
        \caption{Peak memory usage}
        \label{fig:memory_mb_comparison_query1}
    \end{subfigure}

    \caption{Time and space overhead of attribute filtering index construction}
    \label{fig:build_index_comparison}
\end{figure}



To investigate the performance of different attribute filtering algorithms during index construction, we evaluate three key metrics in the single-attribute scenario: index construction time, index size, and peak memory usage. Notably, PASE is evaluated exclusively on Audio, GloVe, Msong, and SIFT1M as it supports only data with dimensionality less than 512.

\begin{figure*}
    \centering
        \setlength{\abovecaptionskip}{0cm}
    \setlength{\belowcaptionskip}{-0.4cm}
    \includegraphics[width=\textwidth]{figures/exp/exp_1_1_SingleLabel_1thread.pdf}
    \caption{Single-Attribute Building and Query (single thread) }
    \label{fig:exp_1_1_SingleLabel_1thread}
\end{figure*}

\begin{figure*}
    \centering
    \setlength{\abovecaptionskip}{0cm}
    \setlength{\belowcaptionskip}{-0.4cm}
    \includegraphics[width=\textwidth]{figures/exp/exp_1_2_SingleLabel_16thread.pdf}
    \caption{Single-Attribute Building and Query (16 threads)}
    \label{fig:exp_1_2_SingleLabel_16thread}
\end{figure*}

\textit{\textbf{Index construction time.}}
As shown in Figure~\ref{fig:build_time_comparison_query1}, among the aforementioned four datasets, PASE has the longest index construction time due to its single-threaded indexing support. Additionally, VBASE also supports only single-threaded indexing but achieves better query performance than PASE.

For algorithms supporting 32-thread, index construction time differences are negligible on small-scale datasets (Audio and Enron) due to their limited complexity. On large-scale datasets (SIFT1M, GIST1M, GloVe, and Msong), ACORN-1 achieves the fastest index construction. This efficiency stems from its similarity to the original HNSW construction process and the use of a limited number of candidate neighbors. In contrast, ACORN-$\gamma$ incurs the highest index construction time, as it expands neighbor lists and evaluates a large candidate pool, leading to increased computational overhead.


\textit{\textbf{Index size.}}
Traditional graph-based methods often only evaluate the size of the generated graph index and do not include the original data, while the index generated by the IVF-based method includes the original data. In order to unify the comparison standard, 
we include both the index structure generated by the algorithm and the original data when evaluating the index size. 
% Traditional graph-based methods often evaluate only the size of the generated index, excluding the original data, whereas IVF-based methods include it. To ensure a consistent comparison, we consider both the index structure and the original data when measuring index size.
As shown in the figure~\ref{fig:index_size_mb_comparison_query1}, PASE exhibits significantly larger index sizes across all supported datasets. This overhead stems primarily from its extensive metadata requirements. The index sizes of other methods show minimal variation. Among these, Faiss generates slightly smaller indexes due to its efficient index design.



\textit{\textbf{Peak memory usage.}}
As shown in Figure~\ref{fig:memory_mb_comparison_query1}, on small-scale datasets, all methods except NHQ exhibit low memory usage. The substantially higher memory consumption of NHQ is attributed to its graph construction procedure, which requires loading the entire dataset into memory. On large-scale datasets, CPAS exhibits slightly lower memory usage compared to other algorithms. Due to their special characteristics, databases were not included in the peak memory usage testing during index construction.



\subsubsection{Performance Evaluation}


%4.2.2


We next evaluate the query performance of AF-ANN search algorithms, focusing on three main scenarios.

\textit{\textbf{Single-Attribute Building and Single-Attribute Query.}}
In this scenario, we construct the index using a single attribute and issue queries on the same attribute.

\textit{Single-Threaded Search.}  
As shown in Figure~\ref{fig:exp_1_1_SingleLabel_1thread}, under full-recall conditions (recall = 1), search often requires traversing larger candidate sets or deeper graph paths, leading to increased computational cost and a sharp QPS drop for most methods. Despite this, UNG maintains high QPS due to its LNG structure, which eliminates unnecessary online filtering of irrelevant attributes, thereby improving query efficiency. But, UNG slightly underperforms on high-LID datasets such as GloVe. In contrast, CAPS performs better on high-LID datasets but is more sensitive to dataset characteristics. CAPS leverages multi-level spatial partitioning and attribute filtering to efficiently explore sparse spaces, whereas UNG relies on structured attribute organization, which limits its adaptability to sparse high-dimensional distributions.



NHQ, StitchedVamana, and FilteredVamana show similar and stable performance across all datasets. This indicates that joint filtering and search strategies can achieve consistent effectiveness under high-recall requirements. As observed in Figure~\ref{fig:exp_1_1_SingleLabel_1thread}, StitchedVamana outperforms FilteredVamana in query efficiency. The difference arises from their pruning strategies: StitchedVamana applies pruning after merging graphs, allowing nodes to accumulate a richer candidate set; while FilteredVamana applies early pruning, potentially eliminating useful candidates prematurely.

Among all methods, vector database systems (PASE, VBASE, Milvus) perform the worst. These systems target general-purpose scenarios but incur communication latency from network I/O and experience high query processing overhead due to complex query parsing. Additionally, we observe that Faiss+HQI\_Batch outperforms vanilla Faiss, indicating that batch querying via HQI can effectively enhance query performance.

\textit{Multi-Threaded Search.}
As shown in Figure~\ref{fig:exp_1_2_SingleLabel_16thread}, UNG continues to achieve the best performance. Puck performs well on large-scale datasets, but its performance degrades on small datasets. Puck is tailored for large-scale scenarios, and optimizations such as two-level inverted indexing and hierarchical quantization introduce unnecessary overhead on small datasets. 
CAPS maintains a relatively high throughput under multi-threading but exhibits limited adaptability to different datasets. The vector distribution of the dataset affects the construction of its partitioned index.

ACORN performs poorly overall, primarily due to the sensitivity of its hyperparameter $\gamma$ to attribute selectivity. Without careful tuning based on dataset characteristics, it is challenging to construct an effective index.

\textit{\textbf{Multi-Attribute Building and Single-Attribute Query.}}
In this scenario, the index is constructed using multiple attributes but applies filtering condition on only one attribute during query processing.

In database systems (VBASE, PASE, Milvus), when the system builds both B+ tree and vector indexes, queries typically utilize only the B+ tree. Faiss offers an ID filtering mechanism, it operates solely during query execution and does not influence index building. CAPS requires that the number of attributes in a query match those used during index construction. ACORN-1 and ACORN-\(\gamma\) are specifically designed for single-attribute indexing. Hence, they are excluded from this comparison.

\begin{figure}[th]
    \centering
    \setlength{\abovecaptionskip}{0cm}
    \setlength{\belowcaptionskip}{-0.1cm}
    % 上面的图例，居中并可通过 hspace 调整左右位置
    \hspace*{15pt} % 可调整的参数，负值左移，正值右移，例如 -20pt 或 20pt
    \includegraphics[width=0.98\columnwidth]{figures/exp/exp_2_legend.pdf} % 图例图片路径
    \vspace{-10pt} % 使用负值拉近两张图的距离，可以根据需要调整
    
    % 下面的子图，居中显示
    \includegraphics[width=0.8\columnwidth]{figures/exp/exp_2_1.pdf}
    \caption{Effect of Multi-Attribute Index Construction on Single Query Performance. ($S$ denotes single-attribute index construction and single-attribute query; $M$ denotes multi-attribute index construction and single-attribute query)}
    \label{fig:exp_2_1}
    
\end{figure}

\textit{Effect of Multi-Attribute Building on Algorithm Performance (M vs. S).}
As shown in Figure \ref{fig:exp_2_1}, Puck demonstrates nearly no performance degradation. In contrast, the performance of StitchedVamana, FilteredVamana, NHQ, and UNG drops significantly, with the following reasons: FilteredVamana increases the complexity introduced by retaining attribute during index construction; the complexity of StitchedVamana increases because data points may duplicate across multiple subgraphs; The fusion distance of NHQ exhibits sensitivity to the number of attributes, which degrades its effectiveness; UNG employs a distinct construction and search strategy, leading to a significant drop in query performance.



\textit{Performance of Algorithms under Multi-Attribute Building (M vs. M).}  
As shown in \ref{fig:exp_2_1}, Puck achieves the best query performance, surpassing other algorithms by an order of magnitude. It filters out irrelevant results during retrieval rather than searching for more candidates. FilteredVamana performs the worst because its multi-attribute indexing forces neighbor selection to cover multiple attributes, hurting single-attribute query efficiency. This leads to excessive irrelevant node traversal, making it slower than other methods.


\begin{figure*}
        \centering
        \setlength{\abovecaptionskip}{0cm}
        \setlength{\belowcaptionskip}{-0.4cm}
        \includegraphics[width=\textwidth]{figures/exp/exp_4_1_MultiLabel_1thread.pdf}
        \caption{Multi-attribute build and query (single thread)}
        \label{fig:exp_4_1_MultiLabel_1thread}
\end{figure*}

\begin{figure*}
        \centering
        \setlength{\abovecaptionskip}{0cm}
        \setlength{\belowcaptionskip}{-0.4cm}
        \includegraphics[width=\textwidth]{figures/exp/exp_3_1.pdf}
        \caption{Effect of attribute distribution on on query performance (single thread)}
        \label{fig:exp_3_1}
\end{figure*}





\textit{\textbf{Multi-Attribute Building and Multi-Attribute Query.}}  
Compared to single-attribute filtering, multi-attribute joint filtering better reflects real-world application scenarios. To evaluate algorithm performance under such scenario, we construct the index using three uniformly distributed attributes and apply filtering conditions on all three attributes simultaneously during the query process.

As shown in Figure~\ref{fig:exp_4_1_MultiLabel_1thread}, UNG achieves the best performance across all datasets. For IVF-based methods that are not specifically optimized for hybrid query scenarios (Faiss\_IVF and Milvus), their QPS remains relatively stable as the recall varies. Milvus, being a general-purpose system, exhibits comparatively poor performance. In contrast, Faiss—especially when combined with HQI\_Batch—achieves moderate performance. Its original IVF implementation naturally supports pre-filtering and does not suffer from the complexity introduced by an increased number of attributes. In fact, filtering can reduce the effective candidate set, improving efficiency.

The IVF-based algorithm CAPS, optimized for hybrid query scenarios, employs a multi-level partitioning strategy that introduces additional overhead. This overhead negatively impacts performan-\\ce on small datasets. However, on large datasets, the overhead is amortized, and the benefits of attribute-aware partitioning become evident, making CAPS the second-best performer after UNG.

NHQ exhibits mediocre performance overall and performs particularly poorly on small datasets. It relies on fused distance calculations. The fusion distance computation is highly sensitive to the number of attributes involved, thus impacting both efficiency and accuracy under multi-attribute filtering.




\subsubsection{Robustness}In this section, we evaluate the robustness of these algorithms.

\textit{\textbf{Attribute Distribution.}} To comprehensively evaluate performance across different attribute distributions, we generate base and query attribute sets with four representative distributions—long-tailed, normal, power-law, and uniform—across the six datasets described in Section~4.1.1. We evaluate all algorithms under these distributions on each dataset. The performance differences observed for the same algorithm across different datasets are relatively minor. Thus, due to space constraints, we present only the results on SIFT1M.

As illustrated in Figure~\ref{fig:exp_3_1}, the evaluated algorithms exhibit varying degrees of sensitivity to attribute distribution shifts. Specifically, ACORN-1, ACORN-$\gamma$, Milvus, Puck, CAPS, StitchedVamana, and UNG demonstrate strong robustness to such shifts. In contrast, Faiss, FilteredVamana, NHQ, VBASE, and PASE show notable sensitivity.

Among all algorithms, ACORN-\(\gamma\) demonstrates the highest robustness. During its index construction, attribute is mainly used for pruning in the lowest layer graph, while the upper-layer hierarchical navigation graphs remain largely unaffected. As a result, changes in attribute distribution have a limited impact on overall performance.

In contrast, VBASE exhibits the weakest robustness. As a post-filtering system, it performs significantly better under uniform distributions but degrades under long-tailed, normal, and power-law distributions. This degradation stems from the low selectivity of certain attributes in the last three distributions, which increases unnecessary distance computations, thus reducing overall efficiency.

\begin{figure}
    \centering
    \setlength{\abovecaptionskip}{0cm}
    \setlength{\belowcaptionskip}{-0.1cm}
    \includegraphics[width=\columnwidth]{figures/exp/exp_5_1_1_SingleLabel_1thread.pdf}
    \caption{Effect of Single-Attribute Selectivity on Query}
    \label{fig:exp_5_1_1_SingleLabel_1thread}
\end{figure}


\textit{\textbf{Single-Attribute Selectivity.}}
In hybrid queries, different attribute selectivity (AS) levels can significantly affect computational cost and query efficiency, as the algorithm must effectively identify matching data points with specific attributes within a large dataset. AS refers to the proportion of data points in the dataset that share a specific attribute value. For example, an AS of 1\% indicates that only 1\% of the dataset satisfies the given attribute condition. 

To investigate this effect, we evaluate four AS levels (1\%, 25\%, 50\%, and 75\%) on the SIFT1M dataset. Using a single-threaded execution environment, we compare the query performance of 13 algorithms under varying AS conditions, as shown in Figure~\ref{fig:exp_5_1_1_SingleLabel_1thread}.

Experimental results show that UNG achieves the best performance across all AS levels, especially at extremely low AS (1\%). 
This advantage stems from its pre-filtering strategy. Pre-filtering strategy significantly reduces the ANN search space by narrowing down candidates prior to vector computation. In contrast, VBASE performs the worst at 1\% AS due to its post-filtering strategy. Post-filtering strategy first retrieves a large number of candidates and then applies filtering, incurring substantial computational overhead.




\begin{figure*}
    \centering
    
    % 第一行：单独一张大图
    \begin{subfigure}{\textwidth}
        \centering
        \setlength{\abovecaptionskip}{0cm}
        \setlength{\belowcaptionskip}{0cm}
        \includegraphics[width=\textwidth]{figures/exp/exp_5_2_1.pdf}
        \caption{Algorithms optimized for low AS levels.}
        \label{fig:exp_5_2_1}
    \end{subfigure}
    
    \vfill % 增加垂直间距

    % 第二行：两张子图，左侧宽度是右侧的两倍
    \begin{subfigure}{0.66\textwidth} % 2/3 宽度
        \centering
        \setlength{\abovecaptionskip}{0cm}
        \setlength{\belowcaptionskip}{0cm}
        \includegraphics[width=\textwidth]{figures/exp/exp_5_2_2.pdf}
        \caption{Algorithms optimized for high AS levels.}
        \label{fig:exp_5_2_2}
    \end{subfigure}
    \hfill % 增加水平间距
    \begin{subfigure}{0.33\textwidth} % 1/3 宽度
        \centering
        \setlength{\abovecaptionskip}{0cm}
        \setlength{\belowcaptionskip}{0cm}
        \includegraphics[width=\textwidth]{figures/exp/exp_5_2_3.pdf}
        \caption{Algorithms insensitive to AS level.}
        \label{fig:exp_5_2_3}
    \end{subfigure}
    
    \setlength{\abovecaptionskip}{0cm}
    \setlength{\belowcaptionskip}{-0.4cm}
    \caption{Different AS under the same algorithm}
    \label{fig:exp_5_2_combined}
\end{figure*}


According to the query performance trends of different algorithms under varying AS levels, we categorize the algorithms into three groups:

\par
(1) \textit{Algorithms optimized for low AS levels.}  
This category includes ACORN-1, CAPS, StitchedVamana, UNG, Faiss, Puck, and Faiss+HQI\_Batch, as illustrated in Figure~\ref{fig:exp_5_2_1}.

ACORN-1 performs well in low AS scenarios because fewer nodes share the same attribute. This increases the average degree of retained nodes and improves graph connectivity. CAPS efficiently skips irrelevant subpartitions, reducing computational overhead. However, as AS increases, it must process more subpartitions and handle a larger dataset. StitchedVamana optimizes local adjacency using independent subgraphs, enabling fast localization at low AS. However, at higher AS levels, it requires broader global exploration. UNG, Faiss, and Puck all use pre-filtering strategies to shrink the search space in low AS conditions, leading to better performance.

Interestingly, Faiss and Faiss+HQI\_Batch perform worst at the 50\% AS level instead of 75\%, which might seem unexpected. This happens because, when AS decreases from 75\% to 50\%, fewer data points are filtered out. As a result, more clusters must be searched, increasing computational cost.

\par
(2) \textit{Algorithms optimized for high AS levels.}  
This group includes NHQ, FilteredVamana, VBASE, and PASE, as shown in Figure~\ref{fig:exp_5_2_2}.

At low AS levels, NHQ struggles to locate relevant regions efficiently, leading to excessive computations on non-matching nodes. FilteredVamana also performs poorly in these scenarios. Its dynamic pruning strategy makes it difficult to balance vector distance and attribute relevance, resulting in overly restricted search paths.
VBASE relies on post-filtering, which increases computational overhead at low AS. PASE performs poorly at extremely low AS (e.g., 1\%), with recall dropping below 0.2. Its fixed candidate set may not contain enough valid results after filtering, leading to incomplete top-$k$ results and significantly reducing recall.

\par
(3) \textit{Algorithms insensitive to AS level.}  
This group includes Milvus and ACORN-\(\gamma\), as illustrated in Figure~\ref{fig:exp_5_2_3}.

Milvus is mainly limited by system-level communication overhead, such as API latency. As a result, its query performance remains largely unaffected by AS variations. ACORN-\(\gamma\) maintains stable performance across different AS levels by using a higher index construction parameter $\gamma$. This ensures a relatively stable average node degree, even after attribute pruning, minimizing the impact of AS changes on query efficiency.

\begin{figure*}
    \centering
    \setlength{\abovecaptionskip}{0cm}
    \setlength{\belowcaptionskip}{-0.4cm}
    \includegraphics[width=\textwidth]{figures/exp/exp_6_1.pdf}
    \caption{Effect of dataset on Query}
    \label{fig:exp_6_1}
\end{figure*}

%4.2.7

\begin{table}[t]
\centering
\setlength{\abovecaptionskip}{0.05cm}
\caption{Time and space overhead of range filtering index construction}
% \vspace{-7pt}
\label{tab:Range Filtered}
\resizebox{\columnwidth}{!}{
\begin{tabular}{l l c c c c c }
\toprule
\textbf{Dataset} & \textbf{Metric} & \textbf{DSG} & \textbf{IRange} & \textbf{SeRF} & \textbf{UNIFY} & \textbf{WinFilter} \\
\midrule
\multirow{3}{*}{DEEP} 
& Index time(s)  & 4156 & 1128 & \textbf{189.89} & 7510 & 32843 \\
& Index size(GB)  &  4.6 & 0.92 & \textbf{0.80} & 1.43 & 2.41  \\
& Peak memory(GB) &  7.78 & 3.54 & \textbf{1.38} & 2.61 & 7.08   \\
% \cmidrule{1-7}
\midrule
\multirow{3}{*}{YT-Audio} 
& Index time(s)   & 15314 & 1039 & \textbf{187.20} & 5905 & 30904    \\
& Index size(GB)    & 4.3 & \textbf{0.7} & 1.04 & 1.55 & 1.32  \\
& Peak memory(GB)   & 7.5 & 3.16 & \textbf{1.57} & 2.97 & 6.95  \\
\midrule
\multirow{3}{*}{WIT} 
& Index time(s)  & 29492 & 7068 & \textbf{828.12} & 28759 & 94909\\
& Index size(GB) &  4.2 & \textbf{1.5 }& 15.34 & 8.71 & 1.59  \\
& Peak memory(GB)  & 21.7 & \textbf{12.32} & 15.87 & 24.38 & 15.29\\
% \cmidrule{1-7}
\bottomrule
\end{tabular}
}
\end{table}

\textit{\textbf{Different Datasets .}}  
To evaluate the performance of various methods across different datasets, we conduct experiments on six datasets. Our analysis focuses on performance variations concerning dataset size, LID, and vector dimensionality.

As shown in Figure~\ref{fig:exp_6_1}, all methods achieve their highest QPS and recall on Audio dataset.Because Audio has small scale, low dimensionality, and low LID.In contrast,all methods exhibit the lowest QPS and recall on the GIST1M and GloVe dataset. Because these two dataset have the largest scale and highest LID.

SIFT1M and Msong are similar datasets, with the key difference being that SIFT1M has lower dimensionality. The four algorithms (ACORN,Faiss,PASE, and NHQ) perform similarly on these two datasets, suggesting strong robustness to high dimensional dataset. In contrast, the remaining algorithms exhibit degraded performance on Msong, revealing a lack of adaptability to high dimensional dataset.

Most algorithms struggle to achieve high recall on GloVe,because it has the highest LID. Compare to other algorithms, the four algorithms (UNG, Faiss, CAPS, and Milvus) manage to maintain relatively high recall, demonstrating better adaptability to complex datasets. Notably, although vanilla Faiss performs worse on SIFT1M compared to Enron dataset, Faiss+HQI\_Batch outperforms on SIFT1M. Because batch optimization in HQI reduces query overhead and increases throughput.


\subsection{Range Filtering}
Although the libraries and databases mentioned above can also implement range filtering, the results are poor, so we will only compare several range filtering algorithms.
\subsubsection{Time and Space overhead of index construction.}


Similar to the evaluation of \textit{Attribute Filtering} algorithms, we also evaluate three key metrics mentioned above in \textit{Range Filtering} algorithms.

\textit{\textbf{Index construction time.}}
As shown in Table \ref{tab:Range Filtered}, SeRF achieves the fastest index construction time among the five algorithms. It incrementally builds the index in attribute order. It requires only a single pass and adds edges within local graphs. The structure is simple, with no redundant operations.

In contrast, WinFilter has the longest construction time. This is mainly due to its tree-based structure, where each node requires an independent nearest neighbor graph. This leads to significant redundant computations and high resource costs, especially for large datasets.
% 如表\ref{tab:Range Filtered}所示，在五种算法中，SeRF的构建时间最短，原因是其按属性值顺序增量构建的方式，仅需一次遍历并在局部图中添加边，结构简单、无冗余操作。而 WinFilter 的构建时间最长，主要由于其采用树状结构，在每个节点上需构建独立的近邻图索引，造成大量重复计算和资源开销，尤其在数据量大时更为明显。






\textit{\textbf{Index size.}} Across the three datasets, IRange maintains a relatively small index size. It builds independent local neighbor graphs within each interval and merges indices dynamically during queries. This prevents space explosion. On low-dimensional datasets (Deep, YT-Audio), SeRF compresses the index using sparse vector distributions, keeping it small. However, in the high-dimensional WIT dataset with high LID, vector connectivity increases. This reduces compression efficiency, leading to a sharp rise in index size. DSG maintains a stable index size across datasets but is generally larger. It uses edge structures with interval labels to support streaming insertions and range queries, increasing storage overhead.


\textit{\textbf{Peak memory usage.}}
In terms of peak memory usage, all five algorithms consume less memory on the first two datasets. However, memory usage increases significantly on WIT, likely due to its high dimensionality.

SeRF achieves the lowest memory usage on low-dimensional datasets. Its Segment Graph efficiently compresses sparse vector spaces. However, on high-dimensional datasets with high LID, the “curse of dimensionality” causes distance concentration. As a result, the index structure of SeRF expands rapidly, reducing compression efficiency.

In contrast, IRange achieves the lowest peak memory usage on WIT. It pre-builds graphs only for a limited number of intervals, avoiding explicit index construction for all possible query ranges. Its index structure remains stable in high dimensions without significant graph growth. This effectively controls index size, making IRange more advantageous for high-dimensional datasets.

\begin{figure*}[htbp]
  \centering
  \setlength{\abovecaptionskip}{0cm}
    \setlength{\belowcaptionskip}{-0.4cm}
  \includegraphics[width=\textwidth]{figures/exp/exp_8_2.pdf}
  \caption{RF-ANN search }
  \label{fig:exp_8_2}
\end{figure*}


\subsubsection{Performance Evaluation. }

In this experiment, we follow the query range definition adopted by prior work~\cite{HQI}. Specifically, for a given query, if the range covers $n/2^i$ data points—where $n$ is the total dataset size—we define the range ratio as $2^{-i}$. Based on this definition, we evaluate algorithm performance under four query range settings: $2^{-2}$, $2^{-4}$, $2^{-6}$, and $2^{-8}$.

Due to space constraints, Figure~\ref{fig:exp_8_2} reports results for only the largest ($2^{-2}$) and smallest ($2^{-8}$) range ratios. The experimental results show that across all datasets (Deep, YT-Audio, and WIT) and query ranges, WinFilter consistently delivers the best performance. This highlights the robustness of its design, which performs ANN search over only relevant tree nodes and merges results efficiently, making it highly effective for static range query scenarios.

iRange offers a good balance between query efficiency and recall, demonstrating stable performance across both datasets and range sizes. In contrast, UNIFY experiences a notable drop in performance under narrow query ranges, suggesting that its HSIG structure—despite incorporating skip lists for pre-filtering—still has limitations in such scenarios. However, by leveraging HNSW and bitmap-based post-filtering, UNIFY performs competitively under broader range conditions, demonstrating strong scalability.

SeRF exhibits relatively weak overall performance, with a significant drop in recall under small-range query scenarios. This suggests that while its compressed graph structure is space-efficient, it has a substantial negative impact on query performance.

It is important to note that this range query experiment is conducted under a fully static setting. Under such conditions, UNIFY, iRange, SeRF, and WinFilter require the dataset to be sorted by attribute prior to index construction. In contrast, DSG  support dynamic index construction with unordered attribute insertions, making them more suitable for streaming or incremental data scenarios. This flexibility highlights their superior extensibility in real-world applications.
\subsubsection{Robustness.}

% \begin{figure*}[htbp]
%     \centering
%     \setlength{\abovecaptionskip}{0cm}
%     \setlength{\belowcaptionskip}{-0.4cm}
%     \includesvg[width=\textwidth]{figures/exp/exp_8_3.svg}
%     \caption{Dataset Effect on RF-ANN Search}
%     \label{fig:exp_8_3}
% \end{figure*}
\begin{figure*}[htbp]
    \centering
    \setlength{\abovecaptionskip}{0cm}
    \setlength{\belowcaptionskip}{-0.5cm}
    \includegraphics[width=\textwidth]{figures/exp/exp_8_3.pdf}
    \caption{Dataset Effect on RF-ANN Search}
    \label{fig:exp_8_3}
\end{figure*}


To examine the robustness of RF-ANNS algorithms, we analyze their performance across different datasets. As shown in Figure~\ref{fig:exp_8_3}, the performance differences. All methods perform worst on WIT, which has the highest LID. On Deep and YT-Audio, which have similar LID, most algorithms achieve comparable performance. 
This suggests that the effectiveness of RF-ANN search is mainly influenced by Lid of the dataset. A higher LID inherently increases the difficulty of hybrid query.

However, the DSG algorithm shows a noticeable performance gap between the Deep and YT-Audio datasets, despite their comparable LID. This indicates that DSG is less robust than other methods when facing dataset-dependent variations, possibly due to its sensitivity to data distribution beyond LID alone.

\section{DISCUSSION}
Based on the performance of the algorithms on different experimental scenarios, we discuss our findings as follows.


\subsection{Recommendations.}
\subsubsection{\textbf{Attribute Filtering}}


\begin{table}[t]
\centering
\setlength{\abovecaptionskip}{0.05cm}
\caption{Algorithm Recommendation per Scenario}
\resizebox{\columnwidth}{!}{
\begin{tabular}{|l|c|c|}
\hline
\textbf{Scenario} & \textbf{Attribute Filtering} & \textbf{Range Filtering}\\
\hline
S1: Large-scale Datasets & Puck, UNG & iRange\\
\hline
S2: Fast Index Construction & ACORN-1, UNG  &SeRF, iRange\\
\hline
S3: Query on Hard Datasets & CAPS, UNG &iRange, DSG\\
\hline
S4: Query on Easy Datasets & StitchedVamana, NHQ & iRange\\

\hline
S5: General-purpose Use & Milvus, Faiss &DSG, UNIFY\\
\hline
S6: Resource-constrained Environments & CAPS, Faiss&SeRF, IRange \\
\hline
S7: High-Recall Querying & UNG & WinFilter \\
\hline
\end{tabular}
}
\label{tab:algo_scenarios}
\vspace{-0.1cm}
\end{table}


We summarize the applicability of different algorithms across various attribute filtering scenarios in Table~\ref{tab:algo_scenarios}.
Puck and UNG excel on large-scale datasets (S1); ACORN-1 and UNG achieve fast index construction (S2); CAPS performs best on hard datasets with high LID (S3), while NHQ, StitchedVamana, and UNG are superior for easy datasets with low LID (S4); Faiss and CAPS can generate relatively compact indexes with low memory usage, which is suitable for resource-constrained situations (S6); Milvus and Faiss serve as general-purpose solutions (S5); UNG stands out for its high recall, precision, and QPS (S7).

\subsubsection{\textbf{Range Filtering}}


% \end{tabular}
% \label{tab:range_algo_scenarios}
% \end{table}
Table~\ref{tab:algo_scenarios} also presents the application scenarios for range filtering. iRange demonstrates strong performance on large-scale datasets, combining efficient construction with excellent query capabilities (S1). For fast index construction, SeRF leads with iRange as a close second (S2). When handling hard datasets, iRange and DSG are recommended (S3), while iRange also performs well on easy datasets (S4). For general-purpose applications, DSG supports dynamic updates while UNIFY provides flexible filtering strategies (S5). Both SeRF and iRange show superior memory efficiency (S6). WinFilter emerges as the optimal choice for high-recall static queries (S7).

\subsection{Challenges}
\subsubsection{\textbf{Attribute Filtering}}
%修改语序
Most existing attribute filtering algorithms are graph-based, %and 
they typically outperform other methods in terms of query accuracy and efficiency. However, graph-based algorithms often incur high indexing costs and significant memory overhead. In contrast, IVF algorithms  generally consume less memory but suffer from limited performance. Filtered−DiskANN leverages disk-based storage, making it more suitable for extremely large-scale datasets even in memory-constrained environments. Moreover, the index construction phase of graph-based algorithms is computationally intensive. Therefore, exploring GPU-based acceleration for graph construction and vector computation during indexing is promising. It can significantly improve the performance of graph-based methods.


Furthermore, current attribute filtering algorithms offer limited support for complex filtering conditions. For example, Filtered-DiskANN  supports single-attribute filtering, and in multi-attribute scenarios, it only supports OR conditions between attributes. 
%The original implementations of 
NHQ and CAPS impose strict constraints on the number of base and query attributes and only support AND conditions. While UNG is relatively flexible—supporting both AND and OR logic—it still lacks support for arbitrary Boolean expressions (e.g., combinations of AND and OR). The lack of flexible Boolean filtering remains a key challenge, limiting the practicality of hybrid query methods in real-world systems with diverse and complex query requirements.

\subsubsection{\textbf{Range Filtering}}

Except for DSG, most Range Filtered algorithms require the dataset to be pre-sorted before building the index. Moreover, these methods do not support multi-attribute range queries. Enhancing these methods to support an arbitrary number of range-filterable attributes remains an open research challenge.

Our experiments show that graph compression methods often lead to poor query performance in RF-ANN search. To address this problem, subsequent algorithms usually optimize the index processing at the segment tree nodes. UNIFY newly proposes segment graphs and integrates multiple data structures to process queries. Although UNIFY performs slightly worse on small-range queries, its proposed index structure broadens the research direction.

It is also worth noting that range filtering and attribute filtering are both forms of hybrid queries. However, aside from vector databases and ACORN, few existing algorithms support both modalities simultaneously. Designing unified frameworks that simultaneously support both is an important research frontier. 

Lastly, our findings show that the distribution and cardinality of attributes, as well as dataset properties (e.g., dimensionality and LID), significantly impact the performance of attribute-filtering methods. Enhancing the robustness of these algorithms under diverse data conditions is another key challenge that warrants further investigation.


\section{CONCLUSION}

In this paper, we evaluate various hybrid query methods, including different algorithms , vector databases, and vector libraries. For attribute filtering algorithms, we design and conduct a series of experiments to comprehensively assess their overall performance. We then perform experiments on six real-world datasets to analyze the effectiveness of attribute filtering algorithms in depth. Additionally, we compare existing range filtering algorithms using three range query datasets. Finally, we provide a detailed analysis of the experimental results, summarize key findings, and highlight areas for improvement. Our study not only validates previous research but also offers insights for future work.



\clearpage

\bibliographystyle{ACM-Reference-Format}
\bibliography{sample}
\end{sloppypar}
\end{document}
\endinput
